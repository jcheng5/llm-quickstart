[
  {
    "objectID": "apps/tool-chat/prompt.html",
    "href": "apps/tool-chat/prompt.html",
    "title": "",
    "section": "",
    "text": "You are an assistant which can convert units and perform basic arithmetic with units."
  },
  {
    "objectID": "quickstart.html#framing-llms",
    "href": "quickstart.html#framing-llms",
    "title": "LLM Quick Start",
    "section": "Framing LLMs",
    "text": "Framing LLMs\n\n\nOur focus: Practical, actionable information\n\nOften, just enough knowledge so you know what to search for (or better yet, what to ask an LLM)\n\nWe will treat LLMs as black boxes\nDon’t focus on how they work (yet)\n\nLeads to bad intuition about their capabilities\nBetter to start with a highly empirical approach"
  },
  {
    "objectID": "quickstart.html#llm-conversations-are-http-requests",
    "href": "quickstart.html#llm-conversations-are-http-requests",
    "title": "LLM Quick Start",
    "section": "LLM Conversations are HTTP Requests",
    "text": "LLM Conversations are HTTP Requests\n\n\nEach interaction is a separate HTTP API request\nThe API server is entirely stateless (despite conversations being inherently stateful!)"
  },
  {
    "objectID": "quickstart.html#example-conversation",
    "href": "quickstart.html#example-conversation",
    "title": "LLM Quick Start",
    "section": "Example Conversation",
    "text": "Example Conversation\n\n“What’s the capital of the moon?”\n\n\"There isn't one.\"\n\n“Are you sure?”\n\n\"Yes, I am sure.\""
  },
  {
    "objectID": "quickstart.html#example-request",
    "href": "quickstart.html#example-request",
    "title": "LLM Quick Start",
    "section": "Example Request",
    "text": "Example Request\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n        {\"role\": \"system\", \"content\": \"You are a terse assistant.\"},\n        {\"role\": \"user\", \"content\": \"What is the capital of the moon?\"}\n    ]\n}'\n\nSystem prompt: behind-the-scenes instructions and information for the model\nUser prompt: a question or statement for the model to respond to"
  },
  {
    "objectID": "quickstart.html#example-response-abridged",
    "href": "quickstart.html#example-response-abridged",
    "title": "LLM Quick Start",
    "section": "Example Response (abridged)",
    "text": "Example Response (abridged)\n{\n  \"choices\": [{\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"The moon does not have a capital. It is not inhabited or governed.\",\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0\n    }\n  }\n}"
  },
  {
    "objectID": "quickstart.html#example-request-1",
    "href": "quickstart.html#example-request-1",
    "title": "LLM Quick Start",
    "section": "Example Request",
    "text": "Example Request\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\"role\": \"system\", \"content\": \"You are a terse assistant.\"},\n      {\"role\": \"user\", \"content\": \"What is the capital of the moon?\"},\n      {\"role\": \"assistant\", \"content\": \"The moon does not have a capital. It is not inhabited or governed.\"},\n      {\"role\": \"user\", \"content\": \"Are you sure?\"}\n    ]\n}'"
  },
  {
    "objectID": "quickstart.html#example-response-abridged-1",
    "href": "quickstart.html#example-response-abridged-1",
    "title": "LLM Quick Start",
    "section": "Example Response (abridged)",
    "text": "Example Response (abridged)\n{\n  \"choices\": [{\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"Yes, I am sure. The moon has no capital or formal governance.\"\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 52,\n    \"completion_tokens\": 15,\n    \"total_tokens\": 67,\n    \"completion_tokens_details\": {\n      \"reasoning_tokens\": 0\n    }\n  }\n}"
  },
  {
    "objectID": "quickstart.html#tokens",
    "href": "quickstart.html#tokens",
    "title": "LLM Quick Start",
    "section": "Tokens",
    "text": "Tokens\n\n\nFundamental units of information for LLMs\nWords, parts of words, or individual characters\n\n“hello” → 1 token\n“unconventional” → 3 tokens: un|con|ventional\n4K video frame at full res → 6885 tokens\n\nImportant for:\n\nModel input/output limits\nAPI pricing is usually by token (see calculator)"
  },
  {
    "objectID": "quickstart.html#instructions",
    "href": "quickstart.html#instructions",
    "title": "LLM Quick Start",
    "section": "Instructions",
    "text": "Instructions\nOpen and run one of these options:\n\n01-basics.R\n01-basics-openai.py (low level library)\n01-basics-langchain.py (high level framework)\n01-basics-chatlas.py (high level framework, similar to R)\n\nIf it errors, now is the time to debug.\nIf it works, study the code and try to understand how it maps to the low-level HTTP descriptions we just went through."
  },
  {
    "objectID": "quickstart.html#summary",
    "href": "quickstart.html#summary",
    "title": "LLM Quick Start",
    "section": "Summary",
    "text": "Summary\n\nA message is an object with a role (“system”, “user”, “assistant”) and a content string\nA chat conversation is a growing list of messages\nThe OpenAI chat API is a stateless HTTP endpoint: takes a list of messages as input, returns a new message as output"
  },
  {
    "objectID": "quickstart.html#shiny-for-r",
    "href": "quickstart.html#shiny-for-r",
    "title": "LLM Quick Start",
    "section": "Shiny for R",
    "text": "Shiny for R\n{shinychat} package\nhttps://github.com/jcheng5/shinychat\n\nDesigned to be used with elmer\nElmer Assistant is quite good for getting started"
  },
  {
    "objectID": "quickstart.html#shiny-for-python",
    "href": "quickstart.html#shiny-for-python",
    "title": "LLM Quick Start",
    "section": "Shiny for Python",
    "text": "Shiny for Python\nUse the official ui.Chat component for Shiny for Python\n\nAsk Shiny assistant for help (ping me or Winston if you need us to approve your invite)\nDo NOT use the older ChatStream component"
  },
  {
    "objectID": "quickstart.html#other-python-frameworks",
    "href": "quickstart.html#other-python-frameworks",
    "title": "LLM Quick Start",
    "section": "Other Python frameworks",
    "text": "Other Python frameworks\n\nStreamlit has an excellent chat component with a nice LangChain integration\nGradio has a chat component that is extremely easy to use"
  },
  {
    "objectID": "quickstart.html#what-is-tool-calling",
    "href": "quickstart.html#what-is-tool-calling",
    "title": "LLM Quick Start",
    "section": "What is Tool Calling?",
    "text": "What is Tool Calling?\n\n\nAllows LLMs to interact with other systems\nSounds complicated? It isn’t!\nSupported by most of the newest LLMs, but not all (notably, not the new OpenAI o1 models, yet)"
  },
  {
    "objectID": "quickstart.html#how-it-works",
    "href": "quickstart.html#how-it-works",
    "title": "LLM Quick Start",
    "section": "How It Works",
    "text": "How It Works\n\n\nNot like this - with the assistant executing stuff\nYes like this\n\nUser asks assistant a question; includes metadata for available tools\nAssistant asks the user to invoke a tool, passing its desired arguments\nUser invokes the tool, and returns the output to the assistant\nAssistant incorporates the tool’s output as additional context for formulating a response"
  },
  {
    "objectID": "quickstart.html#how-it-works-1",
    "href": "quickstart.html#how-it-works-1",
    "title": "LLM Quick Start",
    "section": "How It Works",
    "text": "How It Works\nAnother way to think of it:\n\nThe client can perform tasks that the assistant can’t do\nTools put control into the hands of the assistant—it decides when to use them, and what arguments to pass in, and what to do with the results\nHaving an “intelligent-ish” coordinator of tools is a surprisingly general, powerful capability!"
  },
  {
    "objectID": "quickstart.html#openai-models",
    "href": "quickstart.html#openai-models",
    "title": "LLM Quick Start",
    "section": "OpenAI models",
    "text": "OpenAI models\n\nGPT-4o: best general purpose model\nGPT-4o-mini: similar to 4o, but faster and cheaper (and dumber)\no1-preview: uses chain of thought (available via API only for high usage tiers)\no1-mini"
  },
  {
    "objectID": "quickstart.html#anthropic-models",
    "href": "quickstart.html#anthropic-models",
    "title": "LLM Quick Start",
    "section": "Anthropic models",
    "text": "Anthropic models\n\nClaude 3.5 Sonnet: best model for code generation\nClaude 3.5 Haiku: faster, cheaper (and dumber) than Sonnet"
  },
  {
    "objectID": "quickstart.html#llama-models",
    "href": "quickstart.html#llama-models",
    "title": "LLM Quick Start",
    "section": "Llama models",
    "text": "Llama models\n\nOpen weights: you can download the model\nCan run locally, for example with Ollama\nLlama 3.1 405b: text, 229GB\nLlama 3.1 80b: text, 40GB\nLlama 3.1 8b: text, 4.7GB (can run comfortably on Macbook Pro)\nLlama 3.2 3b: text, 2GB\nLlama 3.2 1b: text, 0.8GB\nCan also access these models via API with Openrouter, Groq, Hugging Face"
  },
  {
    "objectID": "quickstart.html#prompt-engineering-directing-behavioroutput",
    "href": "quickstart.html#prompt-engineering-directing-behavioroutput",
    "title": "LLM Quick Start",
    "section": "Prompt engineering: Directing behavior/output",
    "text": "Prompt engineering: Directing behavior/output\n\n“Respond with just the minimal information necessary.”\n“Explain your response in detail.”\n“Think through this step-by-step.”\n“Carefully read and follow these instructions…”\n“If the user asks a question related to data processing, produce R code to accomplish that task.”\n“Be careful to only provide answers that you are sure about. If you are uncertain about an answer, say so.”"
  },
  {
    "objectID": "quickstart.html#prompt-engineering-using-examples-to-guide-behavior",
    "href": "quickstart.html#prompt-engineering-using-examples-to-guide-behavior",
    "title": "LLM Quick Start",
    "section": "Prompt engineering: Using examples to guide behavior",
    "text": "Prompt engineering: Using examples to guide behavior\n\nGoal: Extract ingredient list from recipe and return in a structured format.\nExample user input:\nIn a large bowl, cream together 1 cup of softened unsalted butter and ½ cup of white sugar until smooth. Beat in 1 egg and 1 teaspoon of vanilla extract. Gradually stir in 2 cups of all-purpose flour until the dough forms. Finally, fold in 1 cup of semisweet chocolate chips. Drop spoonfuls of dough onto an ungreased baking sheet and bake at 350°F (175°C) for 10-12 minutes, or until the edges are lightly browned. Let the cookies cool on the baking sheet for a few minutes before transferring to a wire rack to cool completely. Enjoy!"
  },
  {
    "objectID": "quickstart.html#system-prompt-1-just-instructions",
    "href": "quickstart.html#system-prompt-1-just-instructions",
    "title": "LLM Quick Start",
    "section": "System prompt 1: just instructions",
    "text": "System prompt 1: just instructions\nThe user input contains a recipe. Extract a list of ingredients and return it in JSON format.\nAssistant response:\n{\n  \"ingredients\": [\n    \"1 cup of softened unsalted butter\",\n    \"½ cup of white sugar\",\n    \"1 egg\",\n    \"1 teaspoon of vanilla extract\",\n    \"2 cups of all-purpose flour\",\n    \"1 cup of semisweet chocolate chips\"\n  ]\n}"
  },
  {
    "objectID": "quickstart.html#system-prompt-2-detailed-description-of-output",
    "href": "quickstart.html#system-prompt-2-detailed-description-of-output",
    "title": "LLM Quick Start",
    "section": "System prompt 2: detailed description of output",
    "text": "System prompt 2: detailed description of output\nThe user input contains a recipe. Extract a list of ingredients and return it in JSON format. It should be an array of objects, where each object has keys `ingredient`, `quantity`, and `unit`. Put each object on one line of output.\nAssistant response:\n[\n    {\"ingredient\": \"unsalted butter\", \"quantity\": 1, \"unit\": \"cup\"},\n    {\"ingredient\": \"white sugar\", \"quantity\": 1/2, \"unit\": \"cup\"},\n    {\"ingredient\": \"egg\", \"quantity\": 1, \"unit\": \"large\"},\n    {\"ingredient\": \"vanilla extract\", \"quantity\": 1, \"unit\": \"teaspoon\"},\n    {\"ingredient\": \"all-purpose flour\", \"quantity\": 2, \"unit\": \"cups\"},\n    {\"ingredient\": \"semisweet chocolate chips\", \"quantity\": 1, \"unit\": \"cup\"}\n]"
  },
  {
    "objectID": "quickstart.html#system-prompt-3-one-shot-example",
    "href": "quickstart.html#system-prompt-3-one-shot-example",
    "title": "LLM Quick Start",
    "section": "System prompt 3: one-shot example",
    "text": "System prompt 3: one-shot example\nThe user input contains a recipe. Extract a list of ingredients and return it in JSON format.\n\nExample Output:\n\n```json\n[\n    { \"ingredient\": \"Flour\", \"quantity\": 1, \"unit\": \"cup\" },\n    { \"ingredient\": \"Vegetable oil\", \"quantity\": 0.5, \"unit\": \"tsp\" },\n    { \"ingredient\": \"Onion\", \"quantity\": 1, \"unit\": null },\n]\n```\nAssistant response:\n[\n    { \"ingredient\": \"Unsalted butter\", \"quantity\": 1, \"unit\": \"cup\" },\n    { \"ingredient\": \"White sugar\", \"quantity\": 0.5, \"unit\": \"cup\" },\n    { \"ingredient\": \"Egg\", \"quantity\": 1, \"unit\": null },\n    { \"ingredient\": \"Vanilla extract\", \"quantity\": 1, \"unit\": \"teaspoon\" },\n    { \"ingredient\": \"All-purpose flour\", \"quantity\": 2, \"unit\": \"cups\" },\n    { \"ingredient\": \"Semisweet chocolate chips\", \"quantity\": 1, \"unit\": \"cup\" }\n]"
  },
  {
    "objectID": "quickstart.html#adding-contextknowledge-to-prompt",
    "href": "quickstart.html#adding-contextknowledge-to-prompt",
    "title": "LLM Quick Start",
    "section": "Adding context/knowledge to prompt",
    "text": "Adding context/knowledge to prompt\n\nAdd documentation files to prompt\nAdd positive examples (negative examples don’t work well)\nDocs must fit in context window\nExamples\n\nElmer assistant uses README files in prompt\nSidebot\nFastHTML LLM prompt"
  },
  {
    "objectID": "quickstart.html#rag-retrieval-augmented-generation",
    "href": "quickstart.html#rag-retrieval-augmented-generation",
    "title": "LLM Quick Start",
    "section": "RAG: Retrieval Augmented Generation",
    "text": "RAG: Retrieval Augmented Generation\n\nUseful when documents don’t fit into context window\nSteps:\n\nUser sends query to app: “How do I …?”\nApp retrieves relevant chunks of text via search\nApp sends text and query to LLM\n\n&lt;chunk 1&gt;, &lt;chunk 2&gt;, &lt;chunk 3&gt;. How do I …?\n\nLLM responds with answer\n\nSearch method typically a semantic instead of keyword search, using vector DB\nLLM will only know about chunks that were retrieved; does not “know” entire corpus\nIn general, prompt engineering works better, if docs fit in context window"
  },
  {
    "objectID": "quickstart.html#fine-tuning",
    "href": "quickstart.html#fine-tuning",
    "title": "LLM Quick Start",
    "section": "Fine tuning",
    "text": "Fine tuning\n\nUpdate weights for an existing model with new information\nNot all models can be fine-tuned\nData must be provided in chat conversation format, with query and response\n\nCan’t just feed it documents – this makes fine-tuning more difficult in practice\n\nSupposedly not very effective unless you have a lot of training data"
  },
  {
    "objectID": "quickstart.html#more-on-prompting-rag-fine-tuning",
    "href": "quickstart.html#more-on-prompting-rag-fine-tuning",
    "title": "LLM Quick Start",
    "section": "More on prompting, RAG, fine tuning",
    "text": "More on prompting, RAG, fine tuning\n\nTry prompting first, before RAG and fine tuning.\nOpenAI’s prompt engineering guide\nFine-tuning vs. RAG article"
  },
  {
    "objectID": "quickstart.html#using-posit.cloud",
    "href": "quickstart.html#using-posit.cloud",
    "title": "LLM Quick Start",
    "section": "Using posit.cloud",
    "text": "Using posit.cloud\n\nPosit.cloud workspace with some examples\n\nContains examples from https://github.com/jcheng5/llm-quickstart"
  },
  {
    "objectID": "quickstart.html#going-beyond-chat",
    "href": "quickstart.html#going-beyond-chat",
    "title": "LLM Quick Start",
    "section": "Going beyond chat",
    "text": "Going beyond chat\n\nStructured output can be easily consumed by code: JSON, YAML, CSV, etc.\nUnstructured output cannot: text, images, etc.\n\nLLMs are good at generating unstructured output, but with a little effort, you can get structured output as well."
  },
  {
    "objectID": "quickstart.html#several-techniques-choose-one",
    "href": "quickstart.html#several-techniques-choose-one",
    "title": "LLM Quick Start",
    "section": "Several techniques (choose one)",
    "text": "Several techniques (choose one)\n\nPost-processing: Use a regular expression to extract structured data from the unstructured output (e.g. /```json\\n(.*?)\\n```/)\nSystem prompt: Simply ask the LLM to output structured data. Be clear about what specific format you want, and provide examples—it really helps!\nStructured Output: GPT-4o and GPT-4o-mini now have a first-class Structured Output feature: outputs strictly adhere to a JSON schema you write. (Docs: openai, LangChain)\nTool calling: Create a tool to receive your output, e.g., set_result(object), where its implementation sets some variable. (Works great for elmer.)\nLangChain: Has its own abstractions for parsing unstructured output\n\nAsk #hackathon-08 for help if you’re stuck! (Or ask ChatGPT/Claude to make an example.)"
  },
  {
    "objectID": "quickstart.html#using-images-as-input",
    "href": "quickstart.html#using-images-as-input",
    "title": "LLM Quick Start",
    "section": "Using images as input",
    "text": "Using images as input\n\nModern models are pretty good at this\nCan understand both photographs and plots\nExamples for R and Chatlas are in your repo as 05-vision*\nSee docs for LangChain multimodal, OpenAI vision"
  },
  {
    "objectID": "quickstart.html#past-cohort-projects",
    "href": "quickstart.html#past-cohort-projects",
    "title": "LLM Quick Start",
    "section": "Past cohort projects",
    "text": "Past cohort projects\n\nCohort 1\nCohort 2\nCohort 3\nCohort 4\nCohort 5\nCohort 6"
  },
  {
    "objectID": "quickstart.html#interesting-tools-that-dont-require-coding",
    "href": "quickstart.html#interesting-tools-that-dont-require-coding",
    "title": "LLM Quick Start",
    "section": "Interesting tools that don’t require coding",
    "text": "Interesting tools that don’t require coding\n\nGoogle NotebookLM\nClaude Projects (requires Claude subscription)"
  },
  {
    "objectID": "intro.html#whos-here",
    "href": "intro.html#whos-here",
    "title": "AI Hackathon",
    "section": "Who’s Here",
    "text": "Who’s Here\n\n\nParticipants:\n\nBrian Deitte\nCraig Manning\nGreg Swinehart\nHeath Young\nKevin Gartland\nMichael Chow\nRyan Johnson\nSam Perman\nShannon Hagerty\nToph Allen\n\n\nOrganizers:\n\nAndrew Holz\nJoe Cheng\nWinston Chang"
  },
  {
    "objectID": "intro.html#your-turn",
    "href": "intro.html#your-turn",
    "title": "AI Hackathon",
    "section": "Your Turn",
    "text": "Your Turn\n\nWhat do you do at Posit?\nHow have you used LLMs/AI tools up until now?\nWhat is your skepticism/enthusiasm score (1 to 5)?"
  },
  {
    "objectID": "intro.html#the-plan",
    "href": "intro.html#the-plan",
    "title": "AI Hackathon",
    "section": "The Plan",
    "text": "The Plan\n\n\n\n\n\nNow: Quick Start course on LLMs. You will leave having used a Chat API.\nNext 48 hours: Hack on stuff! Minimum four hours of effort. “Rules” on the next slide.\nThursday: Show & tell, share lessons learned, reflections.\nPost-hackathon:\n\nKeep hacking! (optional)\nThink about how AI might apply to your team\nBe a resource for others around you"
  },
  {
    "objectID": "intro.html#hack-on-stuff",
    "href": "intro.html#hack-on-stuff",
    "title": "AI Hackathon",
    "section": "Hack On Stuff",
    "text": "Hack On Stuff\n\nDoes NOT have to be relevant to your day job, or Posit, or data science.\nThis exercise is about learning and engagement, not ROI.\nDoes NOT have to be a finished product/demo/app/API.\nShowing some things you did in a notebook is fine as long as YOU found it interesting.\nDoes NOT have to use Posit products.\nYou may use any framework, any language,any service that you have access to."
  },
  {
    "objectID": "intro.html#hack-on-stuff-1",
    "href": "intro.html#hack-on-stuff-1",
    "title": "AI Hackathon",
    "section": "Hack On Stuff",
    "text": "Hack On Stuff\n\nDoes NOT have to be an original idea.\nYou can build on existing projects, improve on existing demos, etc.\nDoes NOT even have to be coding.\nDo a deep dive into an AI service or piece of software. Make an interesting project on ChatGPT Playground &gt; Assistants, or assemble a useful NotebookLM and see what its limits are.\nDoes NOT have to be a success.\nNegative results (“I thought LLMs could do this but turns out they can’t”) are useful results as well. But please be prepared to talk about what you tried."
  },
  {
    "objectID": "intro.html#not-a-contest",
    "href": "intro.html#not-a-contest",
    "title": "AI Hackathon",
    "section": "Not a contest",
    "text": "Not a contest\n\nThis is not a competition. There are no prizes, no judging.\nEveryone is coming from different backgrounds and has different levels of experience with AI, with coding, etc.\nThe goal is to learn, to have fun, and to engage with the technology—and share what you learned with others (and not just within this cohort)."
  },
  {
    "objectID": "intro.html#let-it-rip",
    "href": "intro.html#let-it-rip",
    "title": "AI Hackathon",
    "section": "Let It Rip",
    "text": "Let It Rip\n\nAll that said… also feel free to throw down, and make something super cool!\n\n\n\nFour hours is the minimum, not the maximum—if you’re having fun, keep going!"
  },
  {
    "objectID": "intro.html#a-caveat-from-it",
    "href": "intro.html#a-caveat-from-it",
    "title": "AI Hackathon",
    "section": "A Caveat From IT",
    "text": "A Caveat From IT\nNo proprietary code or data is allowed to be sent to any LLM service, with the below exceptions.\n\nGoogle NotebookLM is allowed.\nAWS Bedrock is allowed, and it has Anthropic models. We can help you set this up.\nRunning any local model is allowed, we can help you with this as well.\nSending open source code to any service is allowed."
  },
  {
    "objectID": "02-tools-prompt.html",
    "href": "02-tools-prompt.html",
    "title": "",
    "section": "",
    "text": "You’re hosting a quiz game show.\n\nBefore you start, ask the user to choose a theme.\nAsk simple questions and ask the user to answer them via multiple choice.\nAfter the user answers, provide feedback and then move on to the next question.\nAfter every 5 questions, declare the user to be a winner regardless of their score, lavish them with praise, and start the game over.\nPlay sound effects for each answer, and when the user ‘wins’.\nEmojis are fun, use them liberally!\n\nExample:\n&lt;Assistant&gt;\n  **Question 3:** What is the center of an atom called?\n\n  A) Electron\n  B) Proton\n  C) Neutron\n  D) Nucleus\n\n  Your answer?\n&lt;/Assistant&gt;\n&lt;User&gt;\n  D\n&lt;/User&gt;\n&lt;Assistant&gt;\n  &lt;ToolCall&gt;\n    {\n      id: \"call_1551214\",\n      function: {\n        arguments: \"{sound: 'correct'}\",\n        name: \"play_sound\"\n      },\n      type: \"function\"\n    }\n  &lt;/ToolCall&gt;\n&lt;/Assistant&gt;\n&lt;User&gt;\n  &lt;ToolResponse&gt;\n    {\n      id: \"call_1551214\",\n      result: {\n        success: true,\n        value: null\n      }\n    }\n  &lt;/ToolResponse&gt;\n&lt;/User&gt;\n&lt;Assistant&gt;\n  Correct! The nucleus is the center of an atom.\n\n  **Question 4:** ...\n&lt;/Assistant&gt;\""
  },
  {
    "objectID": "apps/basic-chat/prompt.html",
    "href": "apps/basic-chat/prompt.html",
    "title": "",
    "section": "",
    "text": "You are an AI assistant designed to help users with questions about data analysis with R. To answer user questions, you can provide code examples in R. Only answer questions related to data analysis and R."
  }
]